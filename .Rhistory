setwd("~/GitHub/eledata-data-analysis/R Data Mining/Data Mining Projects/Classification-NaiveBayes-SpamFilter")
# 垃圾邮件分类
require(tm)
# 设置数据路径
spam.path <- file.path("data", "spam")
spam2.path <- file.path("data", "spam_2")
easyham.path <- file.path("data", "easy_ham")
easyham2.path <- file.path("data", "easy_ham_2")
hardham.path <- file.path("data", "hard_ham")
hardham2.path <- file.path("data", "hard_ham_2")
# 读取邮件正文, path 表示文件路径和文件名称 /spam/text.txt, 返回文本向量
get.msg <- function(path){
open_file <- file(path, open = "rt", encoding = "latin1")
mail_text <- readLines(open_file) # 读完文件之后，返回向量化文本，mail_text[1] 表示第一行内容
mt_start <- as.numeric(which(mail_text == "")[1] + 1)
mt_len <- as.numeric(length(mail_text))
if(mt_start > mt_len) mt_start = 1
mail_content <- mail_text[seq(mt_start, mt_len, 1)]
close(open_file)
return(paste(mail_content, collapse = "\n"))
}
# 构造词项-文档矩阵 TDM [i,j], 词项i在文档j中出现的次数
get.tdm <- function(doc.vec){
doc.corpus <- Corpus(VectorSource(doc.vec)) # 语料库
control <- list(stopwords = TRUE, removePunctuation = TRUE, removeNumbers = TRUE)
doc.tdm <- TermDocumentMatrix(doc.corpus, control) #计算词项-文档矩阵 TDM，
return(doc.tdm)
}
# 查询词项出现个数
count.word <- function(doc.vec, term){
tdm <- get.tdm(doc.vec)
word.freq <- rowSums(as.matrix(tdm))
term.freq <- word.freq[which(names(word.freq) == term)]
return (ifelse(length(term.freq) > 0, term.freq, 0))
}
# 检验垃圾邮件
classify.email <- function(doc.vec, train.df, prior = 0.5, c = 1e-6){
tdm <- get.tdm(doc.vec)
msg.freq <- rowSums(as.matrix(tdm))
msg.match <- interaction(names(msg.freq), train.df$term)
if(length(msg.match)){
return (prior*c^(length(msg.freq)))
}else{
# 利用贝叶斯定理来求解
match.probs <- train.df$occurrence[match(msg.match, train.df$term)]
return(prior * prod(match.probs) * c ^ (length(msg.freq) - length(msg.match)))
}
}
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs != "cmds")]
all.spam <- sapply(spam.docs,
function(p) get.msg(file.path(spam.path, p)))
# 邮件正文提取完毕
head(all.spam)
spam.tdm <- get.tdm(all.spam) # 1. 词项-文档矩阵
spam.tdm.mat <- as.matrix(spam.tdm) # 2. 矩阵化
word.freq <- rowSums(spam.tdm.mat)
head(word.freq)
head(spam.tdm.mat)
get.msg <- function(path){
open_file <- file(path, open = "rt", encoding = "latin1")
mail_text <- readLines(open_file) # 读完文件之后，返回向量化文本，mail_text[1] 表示第一行内容
mt_start <- as.numeric(which(mail_text == "")[1] + 1)
mt_len <- as.numeric(length(mail_text))
if(mt_start > mt_len) mt_start = mt_len - 1
mail_content <- mail_text[seq(mt_start, mt_len, 1)]
close(open_file)
return(paste(mail_content, collapse = "\n"))
}
# 1. Spam 文本向量
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs != "cmds")]
all.spam <- sapply(spam.docs,
function(p) get.msg(file.path(spam.path, p)))
# 邮件正文提取完毕
head(all.spam)
spam.tdm <- get.tdm(all.spam) # 1. 词项-文档矩阵
spam.tdm.mat <- as.matrix(spam.tdm) # 2. 矩阵化
word.freq <- rowSums(spam.tdm.mat)
spam.df <- data.frame(cbind(names(word.freq), as.numeric(word.freq)), stringsAsFactors = FALSE)
head(spam.df)
names(spam.df) <- c("term", "frequency") # 3. 添加名称
spam.df$frequency <- as.numeric(spam.df$frequency)
spam.occurrence <- sapply(1:nrow(spam.tdm.mat),
function(i)
{
length(which(spam.tdm.mat[i, ] > 0)) / ncol(spam.tdm.mat)
})
head(spam.occurrence)
spam.density <- spam.df$frequency/sum(spam.df$frequency)
spam.df <- transform(spam.df, density = spam.density, occurrence = spam.occurrence)
head(spam.df)
easyham.docs <- dir(easyham.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
all.easyham <- sapply(easyham.docs,
function(p) get.msg(file.path(easyham.path, p)))
# 邮件正文提取完毕
head(all.easyham)
# 信息整理
easyham.tdm <- get.tdm(all.easyham) # 1. 词项-文档矩阵
easyham.tdm.mat <- as.matrix(easyham.tdm) # 2. 矩阵化
easyham.word.freq <- rowSums(easyham.tdm.mat)
easyham.df <- data.frame(cbind(names(easyham.word.freq), as.numeric(easyham.word.freq)), stringsAsFactors = FALSE)
head(easyham.df)
names(easyham.df) <- c("term", "frequency") # 3. 添加名称
easyham.df$frequency <- as.numeric(easyham.df$frequency)
easyham.occurrence <- sapply(1:nrow(easyham.tdm.mat),
function(i)
{
length(which(easyham.tdm.mat[i, ] > 0)) / ncol(easyham.tdm.mat)
})
head(easyham.occurrence)
easyham.density <- easyham.df$frequency/sum(easyham.df$frequency)
easyham.df <- transform(spam.df, density = easyham.density, occurrence = easyham.occurrence)
head(easyham.df)
hardham.docs <- dir(hardham.path)
hardham.docs <- hardham.docs[which(hardham.docs != "cmds")]
all.hardham <- sapply(hardham.docs,
function(p) get.msg(file.path(hardham.path, p)))
# 邮件正文提取完毕
head(all.hardham)
hardham.tdm <- get.tdm(all.hardham) # 1. 词项-文档矩阵
hardham.tdm.mat <- as.matrix(hardham.tdm) # 2. 矩阵化
hardham.word.freq <- rowSums(hardham.tdm.mat)
hardham.df <- data.frame(cbind(names(hardham.word.freq), as.numeric(hardham.word.freq)), stringsAsFactors = FALSE)
head(hardham.df)
names(hardham.df) <- c("term", "frequency") # 3. 添加名称
hardham.df$frequency <- as.numeric(hardham.df$frequency)
hardham.occurrence <- sapply(1:nrow(hardham.tdm.mat),
function(i)
{
length(which(hardham.tdm.mat[i, ] > 0)) / ncol(hardham.tdm.mat)
})
head(hardham.occurrence)
# 3. hardham 文本向量
hardham.docs <- dir(hardham.path)
hardham.docs <- hardham.docs[which(hardham.docs != "cmds")]
all.hardham <- sapply(hardham.docs,
function(p) get.msg(file.path(hardham.path, p)))
# 邮件正文提取完毕
head(all.hardham)
# use classify function for testing
hardham.spamtest <- classify.email(all.hardham, train.df = spam.df)
hardham.easyhamtest <- classify.email(all.hardham, train.df = easyham.df)
hardham.res <- ifelse(hardham.spamtest > hardham.easyhamtest,
TRUE,
FALSE)
summary(hardham.res)
hardham.spamtest <- classify.email(all.hardham, train.df = spam.df)
R.version$arch
setwd("~/GitHub/eledata-data-analysis/R Data Mining/Data Mining Projects/Classification-NaiveBayes-SpamFilter")
# 垃圾邮件分类
require(tm)
# 设置数据路径
spam.path <- file.path("data", "spam")
spam2.path <- file.path("data", "spam_2")
easyham.path <- file.path("data", "easy_ham")
easyham2.path <- file.path("data", "easy_ham_2")
hardham.path <- file.path("data", "hard_ham")
hardham2.path <- file.path("data", "hard_ham_2")
# 读取邮件正文, path 表示文件路径和文件名称 /spam/text.txt, 返回文本向量
get.msg <- function(path){
open_file <- file(path, open = "rt", encoding = "latin1")
mail_text <- readLines(open_file) # 读完文件之后，返回向量化文本，mail_text[1] 表示第一行内容
mt_start <- as.numeric(which(mail_text == "")[1] + 1)
mt_len <- as.numeric(length(mail_text))
if(mt_start > mt_len) mt_start = mt_len - 1
mail_content <- mail_text[seq(mt_start, mt_len, 1)]
close(open_file)
return(paste(mail_content, collapse = "\n"))
}
# 构造词项-文档矩阵 TDM [i,j], 词项i在文档j中出现的次数
get.tdm <- function(doc.vec){
doc.corpus <- Corpus(VectorSource(doc.vec)) # 语料库
control <- list(stopwords = TRUE, removePunctuation = TRUE, removeNumbers = TRUE)
doc.tdm <- TermDocumentMatrix(doc.corpus, control) #计算词项-文档矩阵 TDM，
return(doc.tdm)
}
# 查询词项出现个数
count.word <- function(doc.vec, term){
tdm <- get.tdm(doc.vec)
word.freq <- rowSums(as.matrix(tdm))
term.freq <- word.freq[which(names(word.freq) == term)]
return (ifelse(length(term.freq) > 0, term.freq, 0))
}
# 检验垃圾邮件
classify.email <- function(doc.vec, train.df, prior = 0.5, c = 1e-6){
tdm <- get.tdm(doc.vec)
msg.freq <- rowSums(as.matrix(tdm))
msg.match <- intersect(names(msg.freq), train.df$term)
if(length(msg.match)){
return (prior*c^(length(msg.freq)))
}else{
# 利用贝叶斯定理来求解
match.probs <- train.df$occurrence[match(msg.match, train.df$term)]
return(prior * prod(match.probs) * c ^ (length(msg.freq) - length(msg.match)))
}
}
# 1. Spam 文本向量
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs != "cmds")]
all.spam <- sapply(spam.docs,
function(p) get.msg(file.path(spam.path, p)))
# 邮件正文提取完毕
head(all.spam)
# 信息整理
spam.tdm <- get.tdm(all.spam) # 1. 词项-文档矩阵
spam.tdm.mat <- as.matrix(spam.tdm) # 2. 矩阵化
word.freq <- rowSums(spam.tdm.mat)
spam.df <- data.frame(cbind(names(word.freq), as.numeric(word.freq)), stringsAsFactors = FALSE)
head(spam.df)
names(spam.df) <- c("term", "frequency") # 3. 添加名称
spam.df$frequency <- as.numeric(spam.df$frequency)
spam.occurrence <- sapply(1:nrow(spam.tdm.mat),
function(i)
{
length(which(spam.tdm.mat[i, ] > 0)) / ncol(spam.tdm.mat)
})
head(spam.occurrence)
spam.density <- spam.df$frequency/sum(spam.df$frequency)
spam.df <- transform(spam.df, density = spam.density, occurrence = spam.occurrence)
head(spam.df)
# 2. easyham 文本向量
easyham.docs <- dir(easyham.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
all.easyham <- sapply(easyham.docs,
function(p) get.msg(file.path(easyham.path, p)))
# 邮件正文提取完毕
head(all.easyham)
# 信息整理
easyham.tdm <- get.tdm(all.easyham) # 1. 词项-文档矩阵
easyham.tdm.mat <- as.matrix(easyham.tdm) # 2. 矩阵化
easyham.word.freq <- rowSums(easyham.tdm.mat)
easyham.df <- data.frame(cbind(names(easyham.word.freq), as.numeric(easyham.word.freq)), stringsAsFactors = FALSE)
head(easyham.df)
names(easyham.df) <- c("term", "frequency") # 3. 添加名称
easyham.df$frequency <- as.numeric(easyham.df$frequency)
easyham.occurrence <- sapply(1:nrow(easyham.tdm.mat),
function(i)
{
length(which(easyham.tdm.mat[i, ] > 0)) / ncol(easyham.tdm.mat)
})
head(easyham.occurrence)
easyham.density <- easyham.df$frequency/sum(easyham.df$frequency)
easyham.df <- transform(spam.df, density = easyham.density, occurrence = easyham.occurrence)
head(easyham.df)
# 3. hardham 文本向量
hardham.docs <- dir(hardham.path)
hardham.docs <- hardham.docs[which(hardham.docs != "cmds")]
all.hardham <- sapply(hardham.docs,
function(p) get.msg(file.path(hardham.path, p)))
# 邮件正文提取完毕
head(all.hardham)
hardham.spamtest <- classify.email(all.hardham, train.df = spam.df)
hardham.easyhamtest <- classify.email(all.hardham, train.df = easyham.df)
hardham.res <- ifelse(hardham.spamtest > hardham.easyhamtest,
TRUE,
FALSE)
summary(hardham.res)
hardham.spamtest
html.spam <- sapply(spam.docs,
function(p) count.word(all.spam, "html"))
head(spam.df[with(spam.df, order(-occurrence)),])
head(easyham.df[with(easyham.df, order(-occurrence)),])
head(all.hardham)
html.easyham <- count.word(all.easyham, "html")
html.easyham
table.easyham <- count.word(all.easyham, "table")
easyham.init <- cbind(html.easyham, table.easyham, "EASYHAM")
easyham.init
head(easyham.df[with(easyham.df, order(-occurrence)),])
init.df <- data.frame(rbind(spam.init, easyham.init),
stringsAsFactors = FALSE)
names(init.df) <- c("html", "table", "type")
init.df$html <- as.numeric(init.df$html)
init.df$table <- as.numeric(init.df$table)
init.df$type <- as.factor(init.df$type)
html.spam <- count.word(all.spam, "html")
table.spam <- count.word(all.spam, "table")
spam.init <- cbind(html.spam, table.spam, "SPAM")
init.df <- data.frame(rbind(spam.init, easyham.init),
stringsAsFactors = FALSE)
names(init.df) <- c("html", "table", "type")
init.df$html <- as.numeric(init.df$html)
init.df$table <- as.numeric(init.df$table)
init.df$type <- as.factor(init.df$type)
init.df
head(all.hardham)
doc.vec <- all.hardham
train.df <- spam.df
prior <- 0.5
c <- 1e-6
tdm <- get.tdm(doc.vec)
msg.freq <- rowSums(as.matrix(tdm))
msg.match <- intersect(names(msg.freq), train.df$term)
if(length(msg.match)){
return (prior*c^(length(msg.freq)))
}else{
# 利用贝叶斯定理来求解
match.probs <- train.df$occurrence[match(msg.match, train.df$term)]
return(prior * prod(match.probs) * c ^ (length(msg.freq) - length(msg.match)))
}
msg.match
if(length(msg.match)){
prop <- prior*c^(length(msg.freq))
}else{
# 利用贝叶斯定理来求解
match.probs <- train.df$occurrence[match(msg.match, train.df$term)]
prop <- prior * prod(match.probs) * c ^ (length(msg.freq) - length(msg.match)))
}
prop
length(msg.match)
classify.email <- function(doc.vec, train.df, prior = 0.5, c = 1e-6){
tdm <- get.tdm(doc.vec)
msg.freq <- rowSums(as.matrix(tdm))
msg.match <- intersect(names(msg.freq), train.df$term)
if(length(msg.match) > 0){
return (prior*c^(length(msg.freq)))
}else{
# 利用贝叶斯定理来求解
match.probs <- train.df$occurrence[match(msg.match, train.df$term)]
return(prior * prod(match.probs) * c ^ (length(msg.freq) - length(msg.match)))
}
}
hardham.spamtest <- classify.email(all.hardham, train.df = spam.df)
hardham.easyhamtest <- classify.email(all.hardham, train.df = easyham.df)
hardham.res <- ifelse(hardham.spamtest > hardham.easyhamtest,
TRUE,
FALSE)
summary(hardham.res)
hardham.spamtest
hardham.easyhamtest
if(length(msg.match) > 0){
prop <- prior*c^(length(msg.freq))
}else{
# 利用贝叶斯定理来求解
match.probs <- train.df$occurrence[match(msg.match, train.df$term)]
prop <- prior * prod(match.probs) * c ^ (length(msg.freq) - length(msg.match)))
}
prop
if(length(msg.match) > 0){
prop <- prior*c^(length(msg.freq))
}else{
# 利用贝叶斯定理来求解
match.probs <- train.df$occurrence[match(msg.match, train.df$term)]
prop <- prior * prod(match.probs) * c ^ (length(msg.freq) - length(msg.match))
}
prop
c
length(msg.freq)
c^(length(msg.freq))
c <- 1e^-6
c ^ (length(msg.freq))
c <- 1e-6
c ^ (length(msg.freq))
c <- 0.000001
c ^ (length(msg.freq))
# 检验垃圾邮件
classify.email <- function(doc.vec, train.df, prior = 0.5, c = 1e-6){
tdm <- get.tdm(doc.vec)
msg.freq <- rowSums(as.matrix(tdm))
msg.match <- intersect(names(msg.freq), train.df$term)
if(length(msg.match) < 1){
return (prior*c^(length(msg.freq)))
}else{
# 利用贝叶斯定理来求解
match.probs <- train.df$occurrence[match(msg.match, train.df$term)]
return(prior * prod(match.probs) * c ^ (length(msg.freq) - length(msg.match)))
}
}
hardham.spamtest <- classify.email(all.hardham, train.df = spam.df)
hardham.easyhamtest <- classify.email(all.hardham, train.df = easyham.df)
hardham.res <- ifelse(hardham.spamtest > hardham.easyhamtest,
TRUE,
FALSE)
summary(hardham.res)
match.probs <- train.df$occurrence[match(msg.match, train.df$term)]
match.probs
prop <- prior * prod(match.probs)
prop
prod(match.probs)
classify.email <- function(doc.vec, train.df, prior = 0.5, c = 1e-6){
tdm <- get.tdm(doc.vec)
msg.freq <- rowSums(as.matrix(tdm))
msg.match <- intersect(names(msg.freq), train.df$term)
if(length(msg.match) < 1)
{
return(prior * c ^ (length(msg.freq)))
}
else
{
# 利用贝叶斯定理来求解
match.probs <- train.df$occurrence[match(msg.match, train.df$term)]
return(prior * prod(match.probs) * c ^ (length(msg.freq) - length(msg.match)))
}
}
hardham.spamtest <- classify.email(all.hardham, train.df = spam.df)
hardham.easyhamtest <- classify.email(all.hardham, train.df = easyham.df)
hardham.res <- ifelse(hardham.spamtest > hardham.easyhamtest,
TRUE,
FALSE)
summary(hardham.res)
print(prod(1:7)) == print(gamma(8))
print(prod(1:7))
gamma(8)
prod(1:7)
prod(1)
prod(1:10)
prod(1:2)
prod(1:3)
prod(1:4)
prod(0.1:0.9)
0.1:0.9
prod(c(0.1,0.2,0.3,0.4))
