p[i] <- q[i] - q[i - 1]
}
p
X <- 0:6
Y <- c(7, 10, 12, 8, 3, 2, 0)
q <- ppois(X, mean(rep(X,Y)))
n <- length(Y)
p[1] <- q[1]
p[n] <- 1 - q[n-1]
for(i in 2:(n - 1)){
p[i] <- q[i] - q[i - 1]
}
p
K
X <- 0:4
Y <- c(7, 10, 12, 8, 5)
q <- ppois(X, mean(rep(X,Y)))
q
n <- length(Y)
n
p[1] <- q[1]
p[n] <- 1 - q[n-1]
for(i in 2:(n - 1)){
p[i] <- q[i] - q[i - 1]
}
p
X <- 0:4
Y <- c(7, 10, 12, 8, 5)
q <- ppois(X, mean(rep(X,Y)))
q
n <- length(Y)
n
p[1] <- q[1]
p[n] <- 1 - q[n-1]
for(i in 2:4){
p[i] <- q[i] - q[i - 1]
}
p
X <- 0:4
Y <- c(7, 10, 12, 8, 5)
q <- ppois(X, mean(rep(X,Y)))
q
n <- length(Y)
n
p[1] <- q[1]
p[n] <- 1 - q[n-1]
for(i in 2:4){
p[i] <- q[i] - q[i - 1]
}
p_len <- length(p)
p_len
for (i in 1:7)
p(i)
p+;em(i)
p_lem(i)
p_len(i)
X <- 0:4
Y <- c(7, 10, 12, 8, 5)
q <- ppois(X, mean(rep(X,Y)))
q
n <- length(Y)
n
p[1] <- q[1]
p[n] <- 1 - q[n-1]
p
X <- 0:4
Y <- c(7, 10, 12, 8, 5)
q <- ppois(X, mean(rep(X,Y)))
q
n <- length(Y)
n
p[1] <- q[1]
p[n] <- 1 - q[n-1]
p
p <- rep(NA, n)
p[1] <- q[1]
p[n] <- 1 - q[n-1]
p
for(i in 2:4){
p[i] <- q[i] - q[i - 1]
}
p
X <- 0:4
Y <- c(7, 10, 12, 8, 5)
q <- ppois(X, mean(rep(X,Y)))
n <- length(Y)
p <- rep(NA, n)
p[1] <- q[1]
p[n] <- 1 - q[n-1]
for(i in 2:(n-2)){
p[i] <- q[i] - q[i - 1]
}
p
chisq.test(Y,p=p)
X <- 0:4
Y <- c(7, 10, 12, 8, 5)
q <- ppois(X, mean(rep(X,Y)))
n <- length(Y)
p <- rep(NA, n)
p[1] <- q[1]
p[n] <- 1 - q[n-1]
for(i in 2:(n-1)){
p[i] <- q[i] - q[i - 1]
}
p
chisq.test(Y,p=p)
x <- c(1,2,3,4,5,6)
y <- c(6,5,4,3,2,1)
cor.test(x,y,method = "spearman")
cor.test(x,y,method = "kendall")
blood <- c(220,188,162,230,145,160,238,188,247,113,126,245,164,231,256,183,190,158,224,175)
mu <- 225
t.test(blood, mu)
t.test(blood, mu = 225)
blood <- c(220,188,162,230,145,160,238,188,247,113,126,245,164,231,256,183,190,158,224,175)
mu <- 225
t.test(blood, mu = mu)
x<-c(1067,919,1196,785,1126,936,918,1156,920,948)
pnorm(1000, mean = mean(x), sd = sd(x))
x<-c(1067,919,1196,785,1126,936,918,1156,920,948)
pnorm(1000, mean = mean(x), sd = sd(x))
x<-c(1067,919,1196,785,1126,936,918,1156,920,948)
p1000 <- 1 - pnorm(1000, mean = mean(x), sd = sd(x))
p1000
test.data <- data.frame(
X = c(113,120,138,120,100,118,138,123,138,116,125,136,110,132,130,110),
A = gl(1,8,16)
)
test.data
test.data <- data.frame(
X = c(113,120,138,120,100,118,138,123,138,116,125,136,110,132,130,110),
A = gl(1,8)
)
test.data
test.data <- data.frame(
X = c(113,120,138,120,100,118,138,123,138,116,125,136,110,132,130,110),
A = gl(2,8,16)
)
test.data
test.aov <- aov(A~X, data = test.data)
summary(test.aov)
test.aov
test.data <- data.frame(
X = c(113,120,138,120,100,118,138,123,138,116,125,136,110,132,130,110),
A = gl(2,8,16)
)
test.data
test.data <- data.frame(
X = c(113,120,138,120,100,118,138,123,138,116,125,136,110,132,130,110),
A = gl(2,8,16)
)
test.data
test.aov <- aov(X~A, data = test.data)
summary(test.aov)
# Home Work
x<-c(113,120,138,120,100,118,138,123)
y<-c(138,116,125,136,110,132,130,110)
wilcox.test(x,y)
x<-c(-0.7,-5.6,2,2.8,0.7,3.5,4,5.8,7.1,-0.5,2.5,-1.6,1.7,3,0.4,4.5,4.6,2.5,6,-1.4)
y<-c(3.7,6.5,5,5.2,0.8,0.2,0.6,3.4,6.6,-1.1,6,3.8,2,1.6,2,2.2,1.2,3.1,1.7,-2)
# Distribution test
shapiro.test(x)
shapiro.test(y)
# KS test
ks.test(x, pnorm, mean(x), sd(x))
ks.test(y, pnorm, mean(y), sd(y))
A <- table(cut(x, br = c(-2,0,2,4,6,8)))
A
p <- c(p[2],p[3]- p[2],1 - p[3])
p
x<-c(-0.7,-5.6,2,2.8,0.7,3.5,4,5.8,7.1,-0.5,2.5,-1.6,1.7,3,0.4,4.5,4.6,2.5,6,-1.4)
y<-c(3.7,6.5,5,5.2,0.8,0.2,0.6,3.4,6.6,-1.1,6,3.8,2,1.6,2,2.2,1.2,3.1,1.7,-2)
# Distribution test
shapiro.test(x)
shapiro.test(y)
# KS test
ks.test(x, pnorm, mean(x), sd(x))
ks.test(y, pnorm, mean(y), sd(y))
# Perrson Test
A <- table(cut(x, br = c(-2,2,4,8)))
p <- pnorm(c(-2,2,4,8), mean(x), sd(x))
p <- c(p[2],p[3]- p[2],1 - p[3])
p
x<-c(-0.7,-5.6,2,2.8,0.7,3.5,4,5.8,7.1,-0.5,2.5,-1.6,1.7,3,0.4,4.5,4.6,2.5,6,-1.4)
y<-c(3.7,6.5,5,5.2,0.8,0.2,0.6,3.4,6.6,-1.1,6,3.8,2,1.6,2,2.2,1.2,3.1,1.7,-2)
# Distribution test
shapiro.test(x)
shapiro.test(y)
# KS test
ks.test(x, pnorm, mean(x), sd(x))
ks.test(y, pnorm, mean(y), sd(y))
# Perrson Test
A <- table(cut(x, br = c(-2,2,4,8)))
p <- pnorm(c(-2,2,4,8), mean(x), sd(x))
p
chisq.test(x, p = p)
x<-c(-0.7,-5.6,2,2.8,0.7,3.5,4,5.8,7.1,-0.5,2.5,-1.6,1.7,3,0.4,4.5,4.6,2.5,6,-1.4)
y<-c(3.7,6.5,5,5.2,0.8,0.2,0.6,3.4,6.6,-1.1,6,3.8,2,1.6,2,2.2,1.2,3.1,1.7,-2)
# Distribution test
shapiro.test(x)
shapiro.test(y)
# KS test
ks.test(x, pnorm, mean(x), sd(x))
ks.test(y, pnorm, mean(y), sd(y))
# Perrson Test
A <- table(cut(x, br = c(-2,2,4,8)))
p <- pnorm(c(-2,2,4,8), mean(x), sd(x))
p
p <- c(p[2],p[3]- p[2],1 - p[3])
p
chisq.test(x, p = p)
chisq.test(A, p = p)
# Hypothesis Test
# 1. For important value test, like mean, sigma.
#P Value Calculation Method
P_Value <- function(cdf, x, paramet = numeric(0), side = 0){
n <- length(paramet)
P <- switch (n + 1,
cdf(x),
cdf(x, paramet),
cdf(x, paramet[1], paramet[2]),
cdf(x, paramet[1], paramet[2], paramet[3])
)
if (side < 0) P # Left side
else if (side > 0) 1 - P # Right side
else
# Two sides, choose lower value.
if(P < 0.5) 2*P
else 2*(1 - P)
}
mean_test1 <- function(x, mu  = 0, sigma = -1, side = 0){
n <- length(x)
xb <- mean(x)
if(sigma > 0){
z <- (xb - mu)/(sigma/sqrt(n))
P <- P_Value(pnorm, z, side = side)
data.frame(mean = xb, df = n, Z = z, P_Value = P)
}else{
t <- (xb - mu)/(sd(x)/sqrt(n))
P <- P_Value(pt, t, paramet = n - 1, side = side)
data.frame(mean = xb, df = n - 1, T = t, P_Value = P)
}
}
X<-c(159, 280, 101, 212, 224, 379, 179, 264,
222, 362, 168, 250, 149, 260, 485, 170)
mean_test1(X, mu = 225, side = 1)
mean_test2 <- function(x, y, var.equal = FALSE, sigma = c(-1, -1), side = 0){
nx <- length(x)
ny <- length(y)
mx <- mean(x)
my <- mean(y)
if(all(sigma > 0)){
z <- (mx - my)/(sqrt(sigma[1]^2/nx + sigma[2]^2/ny)) # Z
P <- P_Value(pnorm, z, side = side)
data.frame(mean = mx - my, df = nx + ny, Z = z, P_Value = P)
}else{
if(var.equal == TRUE){
sw <- sqrt(((nx - 1)*sd(x)^2 + (ny - 1)*sd(x)^2)/(nx + ny - 2)) #SW
t <- (mx - my)/(sw*(sqrt(1/nx + 1/ny)))
nu <- nx + ny - 2
}else{
s1 <- var(x)
s2 <- var(y)
nu <- (s1/nx + s2/ny)^2/(s1^2/(nx^2*(nx - 1)) + s2^2/ny^2*(ny - 1)) # NY
t <- (mx - my)/sqrt(s1/nx + s2/ny)
}
P <- P_Value(pt, t, nu, side = side)
data.frame(mean = mx - my, df = nu, T = t, P_Value = P)
}
}
X<-c(78.1, 72.4, 76.2, 74.3, 77.4, 78.4, 76.0, 75.5, 76.7, 77.3)
Y<-c(79.1, 81.0, 77.3, 79.1, 80.0, 79.1, 79.1, 77.3, 80.2, 82.1)
mean_test2(X,Y, var.equal=TRUE, side=-1)
mean_test2(X,Y, side=-1)
# Standard Deviation Test
# 1. Sigle
var_test1 <- function(x, sigma = 1, mu = Inf, side = 0){
n <- length(x)
if(mu < Inf){
s <- sum(x - mu)^2/n
df = n
}else{
s <- var(x)
df = n - 1
}
k <- df*s/sigma
P <- P_Value(pchisq, k, paramet = df, side = side)
data.frame(var = s, df = df, chisq = k, P_Value = P)
}
var_test1(X, sigma = 3.5)
# 2. Double
var_test2 <- function(x, y, mu = c(Inf, Inf), side = 0){
nx <- length(x)
ny <- length(y)
if(all(mu < Inf)){
sx <- sum(x - mu[1])^2/nx
sy <- sum(y - mu[2])^2/ny
df1 <- nx
df2 <- ny
}else{
sx <- var(x)
sy <- var(y)
df1 <- nx - 1
df2 <- ny - 1
}
f <- sx/sy
P <- P_Value(pf, f, paramet = c(df1, df2), side = side)
data.frame(rate = f, df1 = df1, df2 = df2, F = f, P_Value = P)
}
var_test2(X,Y)
#pearson 鎷熷悎浼樺害鍗℃柟妫€楠?
# 1. 妫€楠屾牱鏈槸鍚︾鍚堟煇鍒嗗竷
#鍒ゆ柇鏌愪釜鎬讳綋鐨勪笉鍚岀殑姘村钩涓嬫槸鍚﹀瓨鍦ㄦ樉钁楀樊寮傘€?
X <- c(210, 312, 170, 85, 223)
n <- sum(X)
m <- length(X)
p <- rep(1/m, m)
K <- sum((X - n*p)^2/(n*p))
K
pr <- 1 - pchisq(K, m - 1)
pr
#妫€楠屾煇涓€讳綋鏄惁绗﹀悎鐞嗚鍒嗗竷
X <- 0:6
Y <- c(7, 10, 12, 8, 3, 2, 0)
q <- ppois(X, mean(rep(X,Y)))
n <- length(Y)
p[1] <- q[1]
p[n] <- 1 - q[n-1]
for(i in 2:(n - 1)){
p[i] <- q[i] - q[i - 1]
}
p
chisq.test(Y,p=p)
X <- 0:4
Y <- c(7, 10, 12, 8, 5)
q <- ppois(X, mean(rep(X,Y)))
n <- length(Y)
p <- rep(NA, n)
p[1] <- q[1]
p[n] <- 1 - q[n-1]
for(i in 2:(n-1)){
p[i] <- q[i] - q[i - 1]
}
p
chisq.test(Y,p=p)
#鍒楄仈琛?
X <- data.frame(
a1 <- c(20, 24, 80, 82),
a2 <- c(22, 38, 104, 125),
a3 <- c(13, 28, 81, 113),
a4 <- c(7, 18, 54, 92)
)
chisq.test(X)
X
as.matrix(X, nrow = 4, ncol = 4)
chisq.test(X)
#Fisher 绮剧‘鐙珛妫€楠?
x <- c(4,5,18,6)
dim(x) <- c(2,2)
fisher.test(x)
# spearman&kendall correlation test, allow non-normal distribution collrelation test.
x <- c(1,2,3,4,5,6)
y <- c(6,5,4,3,2,1)
cor.test(x,y,method = "spearman")
cor.test(x,y,method = "kendall")
# Home Work
# 1
blood <- c(220,188,162,230,145,160,238,188,247,113,126,245,164,231,256,183,190,158,224,175)
mu <- 225
t.test(blood, mu = mu)
# 2
x<-c(1067,919,1196,785,1126,936,918,1156,920,948)
p1000 <- 1 - pnorm(1000, mean = mean(x), sd = sd(x))
p1000
# 3
x<-c(113,120,138,120,100,118,138,123)
y<-c(138,116,125,136,110,132,130,110)
wilcox.test(x,y)
test.data <- data.frame(
X = c(113,120,138,120,100,118,138,123,138,116,125,136,110,132,130,110),
A = gl(2,8,16)
)
test.data
test.aov <- aov(X~A, data = test.data)
summary(test.aov)
# 4
x<-c(-0.7,-5.6,2,2.8,0.7,3.5,4,5.8,7.1,-0.5,2.5,-1.6,1.7,3,0.4,4.5,4.6,2.5,6,-1.4)
y<-c(3.7,6.5,5,5.2,0.8,0.2,0.6,3.4,6.6,-1.1,6,3.8,2,1.6,2,2.2,1.2,3.1,1.7,-2)
# Distribution test
shapiro.test(x)
shapiro.test(y)
# KS test
ks.test(x, pnorm, mean(x), sd(x))
ks.test(y, pnorm, mean(y), sd(y))
# Perrson Test
A <- table(cut(x, br = c(-2,2,4,8)))
p <- pnorm(c(-2,2,4,8), mean(x), sd(x))
p <- c(p[2],p[3]- p[2],1 - p[3])
chisq.test(A, p = p)
mean_test2(x,y, var.equal=TRUE, side=-1)
mean_test2(x,y, side=-1)
var_test2(x,y)
t.test(x,y,var.equal=T)
var.test(x,y)
t.test(x,y,var.equal=F)
x <- c(92,68,28,11,1)
B <- table(cut(x, br = c(0,15,30,70,100)))
B
x <- c(92,68,28,11,1)
B <- table(cut(x, br = c(0,1,2,3,4)))
B
x<-0:5
y<-c(92,68,28,11,1,0)
z <- rep(y,x)
z
x<-0:5
y<-c(92,68,28,11,1,0)
z <- rep(x,y)
z
B <- table(cut(x, br = c(0,1,2,3,4)))
B
x<-0:5
y<-c(92,68,28,11,1,0)
z <- rep(x,y)
B <- table(cut(x, br = c(-1,0,1,2,5)))
B
x<-0:5
y<-c(92,68,28,11,1,0)
z <- rep(x,y)
B <- table(cut(z, br = c(-1,0,1,2,5)))
B
q <- ppois(z, mean(z))
n <- length(z)
p <- rep(NA, n)
p
p[1] <- q[1]
p[n] <- 1 - q[n-1]
for(i in 2:(n-1)){
p[i] <- q[i] - q[i - 1]
}
p
chisq.test(Y,p=p)
chisq.test(A, p = p)
chisq.test(z,p=p)
x<-0:5
y<-c(92,68,28,11,1,0)
z <- rep(x,y)
B <- table(cut(z, br = c(-1,0,1,2,5)))
B
q<-ppois(c(0,1,2,5),mean(z))
p<-c(q[1],q[2]-q[1],q[3]-q[2],1-q[3])
chisq.test(z,p=p)
x<-0:5
y<-c(92,68,28,11,1,0)
z <- rep(x,y)
B <- table(cut(z, br = c(-1,0,1,2,5)))
B
q<-ppois(c(0,1,2,5),mean(z))
p<-c(q[1],q[2]-q[1],q[3]-q[2],1-q[3])
chisq.test(B,p=p)
# Data Description
# Test Data
x <- c(74.3,78.8,68.8,78.0,70.4,80.5,80.5,69.7,71.2,73.5,
79.5,75.6,75.0,78.8,72.0,72.0,72.0,74.3,71.2,72.0,
75.0,73.5,78.8,74.3,75.8,65.0,74.3,71.2,69.7,68.0,
73.5,75.0,72.0,64.3,75.8,80.3,69.7,74.3,73.5,73.5,
75.8,75.8,68.8,76.5,70.4,71.2,81.2,75.0,70.4,68.0,
70.4,72.0,76.5,74.3,76.5,77.6,67.3,72.0,75.0,74.3,
73.5,79.5,73.5,74.7,65.0,76.5,81.6,75.4,72.7,72.7,
67.2,76.5,72.7,70.4,77.2,68.8,67.3,67.3,67.3,72.7,
75.8,73.5,75.0,73.5,73.5,73.5,72.7,81.6,70.3,74.3,
73.5,79.5,70.4,76.5,72.7,77.2,84.3,75.0,76.5,70.4)
# Data source
df_people_info <- data.frame(Name = c("A", "B", "C", "D", "E"),
Sex = c("F", "M", "F", "F", "M"),
Age = c(16, 27, 28, 20, 21),
Height = c(180, 177, 189, 168, 172),
Weight = c(76, 87, 69, 79, 70)
)
df_people_info
incomes <- c(60, 49, 40, 61, 64, 60, 59, 54, 62, 69, 70, 42, 56,
61, 61, 61, 58, 51, 48, 65, 49, 49, 41, 48, 52, 46,
59, 46, 58, 43)
incomes
# 浣嶇疆鐨勫害閲?
# mean sort quantile median
# 鍒嗘暎绋嬪害鐨勫害閲?&鍒嗗竷褰㈢姸鐨勫害閲?
# 鏂瑰樊锛屽彉寮傜郴鏁帮紝 鏋佸樊锛? 鏍囧噯璇紝鍋忓害绯绘暟锛屽嘲搴︾郴鏁?
# mean - 鍧囧€? v - 鏍锋湰鏂瑰樊  s - 鏍囧噯宸? me - 涓綅鏁?
# cv - 鍙樺紓绯绘暟 css - 鏍锋湰鏍℃骞虫柟鍜? uss - 鏍锋湰鏈牎姝ｅ钩鏂瑰拰
# R - 鏋佸樊 R1 - 鍥涘垎浣嶅樊 sm - 鏍锋湰鏍囧噯璇? g1 - 鍋忓害绯绘暟
# g2 - 宄板害绯绘暟
data_outline <- function(x){
n <- length(x)
m <- mean(x)
v <- var(x)
s <- sd(x)
me <- median(x)
cv <- 100*s/m
css <- sum((x - m)^2)
uss <- sum(x^2)
R <- max(x) - min(x)
R1 <- quantile(x, 3/4) - quantile(x, 1/4)
sm <- s/sqrt(n)
g1 <- (n/((n-1)*(n-2)*s^3))*((sum(x-m)^3)/n)
g2 <- ((n*n*(n+1))/((n-1)*(n-2)*(n-3)*(s^4)))*(sum(x-m)^4/n)-(3*(n-1)^2)/((n-2)*(n-3))
data.frame(
N = n, Mean = m, Var = v, SD = s, Median = me, CV = cv, CSS = css, USS = uss, R = R,
R1 = R1, StandardMean = sm, Skewness = g1, Kurtosis = g2, row.names =  1
)
}
data_outline(x)
