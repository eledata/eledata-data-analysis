{
    "contents" : "# Hypothesis Test\n\n# 1. For important value test, like mean, sigma.\n\n#P Value Calculation Method\nP_Value <- function(cdf, x, paramet = numeric(0), side = 0){\n  n <- length(paramet)\n  P <- switch (n + 1,\n    cdf(x),\n    cdf(x, paramet),\n    cdf(x, paramet[1], paramet[2]),\n    cdf(x, paramet[1], paramet[2], paramet[3])\n  )\n  if (side < 0) P # Left side\n  else if (side > 0) 1 - P # Right side\n  else \n    # Two sides, choose lower value.\n    if(P < 0.5) 2*P\n    else 2*(1 - P)\n}\n\nmean_test1 <- function(x, mu  = 0, sigma = -1, side = 0){\n  n <- length(x)\n  xb <- mean(x)\n  if(sigma > 0){\n    z <- (xb - mu)/(sigma/sqrt(n))\n    P <- P_Value(pnorm, z, side = side)\n    data.frame(mean = xb, df = n, Z = z, P_Value = P)\n  }else{\n    t <- (xb - mu)/(sd(x)/sqrt(n))\n    P <- P_Value(pt, t, paramet = n - 1, side = side)\n    data.frame(mean = xb, df = n - 1, T = t, P_Value = P)\n  }\n}\n\nX<-c(159, 280, 101, 212, 224, 379, 179, 264,\n     222, 362, 168, 250, 149, 260, 485, 170)\nmean_test1(X, mu = 225, side = 1)\n\nmean_test2 <- function(x, y, var.equal = FALSE, sigma = c(-1, -1), side = 0){\n  nx <- length(x)\n  ny <- length(y)\n  mx <- mean(x)\n  my <- mean(y)\n  if(all(sigma > 0)){\n    z <- (mx - my)/(sqrt(sigma[1]^2/nx + sigma[2]^2/ny)) # Z \n    P <- P_Value(pnorm, z, side = side)\n    data.frame(mean = mx - my, df = nx + ny, Z = z, P_Value = P)\n  }else{\n    if(var.equal == TRUE){\n      sw <- sqrt(((nx - 1)*sd(x)^2 + (ny - 1)*sd(x)^2)/(nx + ny - 2)) #SW\n      t <- (mx - my)/(sw*(sqrt(1/nx + 1/ny)))\n      nu <- nx + ny - 2\n    }else{\n        s1 <- var(x)\n        s2 <- var(y)\n        nu <- (s1/nx + s2/ny)^2/(s1^2/(nx^2*(nx - 1)) + s2^2/ny^2*(ny - 1)) # NY\n        t <- (mx - my)/sqrt(s1/nx + s2/ny)\n      }\n    P <- P_Value(pt, t, nu, side = side)\n    data.frame(mean = mx - my, df = nu, T = t, P_Value = P)\n  }\n}\n\nX<-c(78.1, 72.4, 76.2, 74.3, 77.4, 78.4, 76.0, 75.5, 76.7, 77.3)\nY<-c(79.1, 81.0, 77.3, 79.1, 80.0, 79.1, 79.1, 77.3, 80.2, 82.1)\n\nmean_test2(X,Y, var.equal=TRUE, side=-1)\nmean_test2(X,Y, side=-1)\n\n# Standard Deviation Test\n\n# 1. Sigle\nvar_test1 <- function(x, sigma = 1, mu = Inf, side = 0){\n  n <- length(x)\n  if(mu < Inf){\n    s <- sum(x - mu)^2/n\n    df = n\n  }else{\n    s <- var(x)\n    df = n - 1\n  }\n  k <- df*s/sigma\n  P <- P_Value(pchisq, k, paramet = df, side = side)\n  data.frame(var = s, df = df, chisq = k, P_Value = P)\n}\nvar_test1(X, sigma = 3.5)\n\n# 2. Double\nvar_test2 <- function(x, y, mu = c(Inf, Inf), side = 0){\n  nx <- length(x)\n  ny <- length(y)\n  if(all(mu < Inf)){\n    sx <- sum(x - mu[1])^2/nx\n    sy <- sum(y - mu[2])^2/ny\n    df1 <- nx\n    df2 <- ny\n  }else{\n    sx <- var(x)\n    sy <- var(y)\n    df1 <- nx - 1\n    df2 <- ny - 1\n  }\n  f <- sx/sy\n  P <- P_Value(pf, f, paramet = c(df1, df2), side = side)\n  data.frame(rate = f, df1 = df1, df2 = df2, F = f, P_Value = P)\n}\n\nvar_test2(X,Y)\n\n#pearson 拟合优度卡方检???\n# 1. 检验样本是否符合某分布\n\n\n#判断某个总体的不同的水平下是否存在显著差异???\nX <- c(210, 312, 170, 85, 223)\nn <- sum(X)\nm <- length(X)\np <- rep(1/m, m)\nK <- sum((X - n*p)^2/(n*p))\nK\npr <- 1 - pchisq(K, m - 1)\npr\n\n#检验某个总体是否符合理论分布\nX <- 0:6\nY <- c(7, 10, 12, 8, 3, 2, 0)\nq <- ppois(X, mean(rep(X,Y)))\nn <- length(Y)\np[1] <- q[1]\np[n] <- 1 - q[n-1]\nfor(i in 2:(n - 1)){\n  p[i] <- q[i] - q[i - 1]\n}\np\nchisq.test(Y,p=p)\n\nX <- 0:4\nY <- c(7, 10, 12, 8, 5)\nq <- ppois(X, mean(rep(X,Y)))\nn <- length(Y)\np <- rep(NA, n)\np[1] <- q[1]\np[n] <- 1 - q[n-1]\nfor(i in 2:(n-1)){\n  p[i] <- q[i] - q[i - 1]\n}\np\nchisq.test(Y,p=p)\n\n\n#列联???\nX <- data.frame(\n  a1 <- c(20, 24, 80, 82),\n  a2 <- c(22, 38, 104, 125),\n  a3 <- c(13, 28, 81, 113),\n  a4 <- c(7, 18, 54, 92)\n)\nchisq.test(X)\nX\nas.matrix(X, nrow = 4, ncol = 4)\nchisq.test(X)\n\n#Fisher 精确独立检???\nx <- c(4,5,18,6)\ndim(x) <- c(2,2)\nfisher.test(x)\n\n# spearman&kendall correlation test, allow non-normal distribution collrelation test.\nx <- c(1,2,3,4,5,6)\ny <- c(6,5,4,3,2,1)\ncor.test(x,y,method = \"spearman\")\ncor.test(x,y,method = \"kendall\")\n\n# Home Work\n\n# 1\n\nblood <- c(220,188,162,230,145,160,238,188,247,113,126,245,164,231,256,183,190,158,224,175)\nmu <- 225\nt.test(blood, mu = mu)\n\n# 2\n\nx<-c(1067,919,1196,785,1126,936,918,1156,920,948)\np1000 <- 1 - pnorm(1000, mean = mean(x), sd = sd(x))\np1000\n\n# 3\n\nx<-c(113,120,138,120,100,118,138,123)\ny<-c(138,116,125,136,110,132,130,110) \nwilcox.test(x,y)\n\ntest.data <- data.frame(\n  X = c(113,120,138,120,100,118,138,123,138,116,125,136,110,132,130,110),\n  A = gl(2,8,16)\n  )\ntest.data\ntest.aov <- aov(X~A, data = test.data)\nsummary(test.aov)\n\n# 4\n\nx<-c(-0.7,-5.6,2,2.8,0.7,3.5,4,5.8,7.1,-0.5,2.5,-1.6,1.7,3,0.4,4.5,4.6,2.5,6,-1.4)\ny<-c(3.7,6.5,5,5.2,0.8,0.2,0.6,3.4,6.6,-1.1,6,3.8,2,1.6,2,2.2,1.2,3.1,1.7,-2)\n\n# Distribution test\nshapiro.test(x)\nshapiro.test(y)\n\n# KS test\nks.test(x, pnorm, mean(x), sd(x))\nks.test(y, pnorm, mean(y), sd(y))\n\n# Pearson Test\nA <- table(cut(x, br = c(-2,2,4,8)))\np <- pnorm(c(-2,2,4,8), mean(x), sd(x))\np <- c(p[2],p[3]- p[2],1 - p[3])\nchisq.test(A, p = p)\n\n# Self function\nmean_test2(x,y, var.equal=TRUE, side=-1)\nmean_test2(x,y, side=-1)\nvar_test2(x,y)\n\n# Sys Internal function\nt.test(x,y,var.equal=T)\nt.test(x,y,var.equal=F)\nvar.test(x,y)\n\n# 5\nx<-0:5\ny<-c(92,68,28,11,1,0) \nz <- rep(x,y)\nB <- table(cut(z, br = c(-1,0,1,2,5))) # Step 1, Split into small interval\nB\nq<-ppois(c(0,1,2,5),mean(z))  # Step 2, fill the vaule into the small interval\np<-c(q[1],q[2]-q[1],q[3]-q[2],1-q[3]) # Step 3, calculate the value for interval\nchisq.test(B,p=p)\n",
    "created" : 1463464802508.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1252360503",
    "id" : "4B024301",
    "lastKnownWriteTime" : 1463463230,
    "path" : "~/GitHub/eledata-data-analysis/R Stats and Model/Hypothesis_Test.R",
    "project_path" : "R Stats and Model/Hypothesis_Test.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}